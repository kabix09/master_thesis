{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01a8400-5267-4dd5-a990-dee8d8f666a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import tempfile\n",
    "import os\n",
    "import random\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec770c-5ba2-4c9d-9f40-48ce2b29d942",
   "metadata": {},
   "source": [
    "## Function generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e701b3a-dbc9-4da1-864c-ab038b53a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process_query(args):\n",
    "    query, settings, file_path = args\n",
    "    process_query(query, settings, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c19690-6f5f-401c-9afa-039e60ebaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirtualAggregator:\n",
    "    def __init__(self):\n",
    "        self.collection = None\n",
    "        self.N = None\n",
    "        self.k = None\n",
    "        self.pn = None\n",
    "        self.chroma_collection = None\n",
    "        self.init_connection()\n",
    "\n",
    "    def set_parameters(self, N, k, pn):\n",
    "        self.N = N\n",
    "        self.k = k\n",
    "        self.pn = pn\n",
    "\n",
    "    def init_connection(self):\n",
    "        collection_status = False\n",
    "        max_retries = 5\n",
    "        retries = 0\n",
    "\n",
    "        while not collection_status and retries < max_retries:\n",
    "            try:\n",
    "                chroma_client = chromadb.HttpClient(host=\"localhost\", port=8000, settings=Settings(allow_reset=True, anonymized_telemetry=False))\n",
    "                self.chroma_collection = chroma_client.get_or_create_collection(name=\"articles_with_score\")\n",
    "                collection_status = True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                retries += 1\n",
    "\n",
    "        if not collection_status:\n",
    "            raise Exception(\"Failed to connect to the collection after 5 attempts\")\n",
    "\n",
    "    def get_similar_articles(self, query, k):\n",
    "        collection_status = False\n",
    "        max_retries = 5\n",
    "        retries = 0\n",
    "\n",
    "        while not collection_status and retries < max_retries:\n",
    "            try:\n",
    "                return self.chroma_collection.query(query_texts=[query], n_results=2*k)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                retries += 1\n",
    "\n",
    "        if not collection_status:\n",
    "            raise Exception(\"Failed to connect to the collection after 5 attempts\")\n",
    "\n",
    "    def distribution_function(self, page_count):\n",
    "        pages_distribution = np.exp(-np.arange(1, page_count + 1))\n",
    "        pages_distribution /= pages_distribution.sum()\n",
    "        return pages_distribution\n",
    "\n",
    "    def distribution_generator(self, collection_dict):\n",
    "        scaler = MinMaxScaler()\n",
    "        values_to_scale = np.array([\n",
    "            collection_dict['year'],\n",
    "            collection_dict['n_citation'],\n",
    "            collection_dict['gov_score']\n",
    "        ]).T\n",
    "\n",
    "        scaled_values = scaler.fit_transform(values_to_scale)\n",
    "        collection_dict['year_normalized'] = scaled_values[:, 0].tolist()\n",
    "        collection_dict['citations_normalized'] = scaled_values[:, 1].tolist()\n",
    "        collection_dict['points_normalized'] = scaled_values[:, 2].tolist()\n",
    "\n",
    "        collection_dict['score'] = [\n",
    "            self.pn[0] * collection_dict['similarity'][i] +\n",
    "            self.pn[1] * collection_dict['year_normalized'][i] +\n",
    "            self.pn[2] * collection_dict['citations_normalized'][i] +\n",
    "            self.pn[3] * collection_dict['points_normalized'][i]\n",
    "            for i in range(len(collection_dict['id']))\n",
    "        ]\n",
    "\n",
    "        sorted_collection = sorted(\n",
    "            [\n",
    "                {\n",
    "                    'id': collection_dict['id'][i],\n",
    "                    'title': collection_dict['title'][i],\n",
    "                    'similarity': collection_dict['similarity'][i],\n",
    "                    'year': collection_dict['year'][i],\n",
    "                    'n_citation': collection_dict['n_citation'][i],\n",
    "                    'gov_score': collection_dict['gov_score'][i],\n",
    "                    'year_normalized': collection_dict['year_normalized'][i],\n",
    "                    'citations_normalized': collection_dict['citations_normalized'][i],\n",
    "                    'points_normalized': collection_dict['points_normalized'][i],\n",
    "                    'score': collection_dict['score'][i]\n",
    "                }\n",
    "                for i in range(len(collection_dict['id']))\n",
    "            ],\n",
    "            key=lambda x: x['score'],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        ranked_indices = [entry['id'] for entry in sorted_collection]\n",
    "        pages = [ranked_indices[i:i + self.N] for i in range(0, len(ranked_indices), self.N)]\n",
    "        pages_distribution = self.distribution_function(len(pages))\n",
    "\n",
    "        np.random.seed(42)\n",
    "        selected_papers = []\n",
    "        for _ in range(self.k):\n",
    "            selected_page_index = np.random.choice(len(pages), p=pages_distribution)\n",
    "            selected_page = pages[selected_page_index]\n",
    "            selected_paper_index = np.random.choice(selected_page)\n",
    "            selected_papers.append(selected_paper_index)\n",
    "\n",
    "            pages[selected_page_index] = [x for x in selected_page if x != selected_paper_index]\n",
    "\n",
    "        selected_paper_counts = collections.Counter(selected_papers)\n",
    "        return selected_paper_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "243aa769-25b8-4a18-9def-b7d5b32c0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query, settings, file_path):\n",
    "    virtual_aggregator = VirtualAggregator()\n",
    "    max_k = max(settings, key=lambda x: x['k'])['k']\n",
    "\n",
    "    result_dict = {\n",
    "        'title': [],\n",
    "        'settings': [],\n",
    "        'distribution': [],\n",
    "    }\n",
    "    \n",
    "    similar_articles = virtual_aggregator.get_similar_articles(query, max_k)\n",
    "\n",
    "    for sample in settings:\n",
    "        virtual_aggregator.set_parameters(sample['N'], sample['k'], sample['pn'])\n",
    "        distribution = step(query, similar_articles, virtual_aggregator)\n",
    "\n",
    "        # Save result\n",
    "        result_dict['title'].append(query)\n",
    "        result_dict['settings'].append(sample)\n",
    "        result_dict['distribution'].append(dict(distribution))\n",
    "\n",
    "    save_results(result_dict, file_path)\n",
    "\n",
    "def step(query, similar_articles, virtual_aggregator):\n",
    "    collection_dict = {\n",
    "        'id': similar_articles['ids'][0],\n",
    "        'title': similar_articles['documents'][0],\n",
    "        'similarity': similar_articles['distances'][0],\n",
    "        'year': [metadata['year'] for metadata in similar_articles['metadatas'][0]],\n",
    "        'n_citation': [metadata['n_citation'] for metadata in similar_articles['metadatas'][0]],\n",
    "        'gov_score': [metadata['gov_score'] for metadata in similar_articles['metadatas'][0]]\n",
    "    }\n",
    "\n",
    "    return virtual_aggregator.distribution_generator(collection_dict)\n",
    "\n",
    "def save_results(result_dict, file_path):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    keys = result_dict.keys()\n",
    "    with open(file_path, 'a', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        if not file_exists:\n",
    "            dict_writer.writeheader()\n",
    "        dict_writer.writerows([dict(zip(keys, row)) for row in zip(*result_dict.values())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d60cc3b1-1e3c-482e-9300-20a176075c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, settings):\n",
    "        self.virtual_aggregator = VirtualAggregator()\n",
    "        self.settings = settings\n",
    "        self.queries = None\n",
    "         \n",
    "    def generate_arguments_with_progress(self, queries, settings, file_path):\n",
    "        def generate_for_query(query, settings, file_path):\n",
    "            return (query, settings, file_path)\n",
    "\n",
    "        results = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(generate_for_query, query, settings, file_path) for query in tqdm(queries, total=len(queries), desc=\"Generating futures\")]\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Generating arguments\"):\n",
    "                results.append(future.result())\n",
    "    \n",
    "        return results\n",
    "\n",
    "    def run_experiment(self):\n",
    "        self.load_queries()\n",
    "        print(f\"Loaded: {len(self.queries)} queries\")\n",
    "    \n",
    "        file_path = '../data/results.csv'\n",
    "        pool_args = self.generate_arguments_with_progress(self.queries, self.settings, file_path)\n",
    "        with Pool(cpu_count()-7) as pool:\n",
    "            for _ in tqdm(pool.imap_unordered(run_process_query, pool_args), total=len(pool_args), desc=\"Queries\", unit=\"query\"):\n",
    "                pass\n",
    "\n",
    "    def load_queries(self):\n",
    "        df_query = pd.read_csv('../data/queries_df.csv')\n",
    "        self.queries = df_query['Query'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04bdb7f-f9dd-4d29-928f-325f1bf8e6b8",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9aac17-9cb6-40a5-a467-14f0e478afb2",
   "metadata": {},
   "source": [
    "## 1. Health test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440d9bd-c137-4d5e-9a8f-1af9eed87a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 850000 queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating futures: 100%|███████████████████████████████████████████████████| 850000/850000 [00:34<00:00, 24799.44it/s]\n",
      "Generating arguments: 100%|████████████████████████████████████████████████| 850000/850000 [00:05<00:00, 154764.08it/s]\n",
      "Queries:   0%|                                                                           | 0/850000 [00:00<?, ?query/s]"
     ]
    }
   ],
   "source": [
    "# Parametry wirtualnego agregatora\n",
    "settings = [\n",
    "    {\n",
    "        'N': 20,\n",
    "        'k': 10,\n",
    "        'pn': [0.5, 0.3, 0.1, 0.1],\n",
    "    },\n",
    "    {\n",
    "        'N': 20,\n",
    "        'k': 15,\n",
    "        'pn': [0.5, 0.2, 0.2, 0.1],\n",
    "    },\n",
    "]\n",
    "\n",
    "experiment = Experiment(settings)\n",
    "experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd4186-07d9-4707-870d-5111933552fd",
   "metadata": {},
   "source": [
    "## 2. Fill experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ecdf0ea-1650-4919-a5bc-efad413ea86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples_with_fixed_pn(num_examples):\n",
    "    examples = []\n",
    "    for _ in range(num_examples):\n",
    "        N = np.random.randint(10, 30)\n",
    "        k = np.random.randint(5, N)\n",
    "        pn = np.random.dirichlet(np.ones(4), size=1)[0]\n",
    "        pn = np.round(pn, 2).tolist()\n",
    "        examples.append({\n",
    "            'N': N,\n",
    "            'k': k,\n",
    "            'pn': pn,\n",
    "        })\n",
    "    return examples\n",
    "\n",
    "settings = generate_examples_with_fixed_pn(500)\n",
    "#display(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e90856-e23e-4f4f-93a2-c1c99cb8ff52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 850000 queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating futures: 100%|███████████████████████████████████████████████████| 850000/850000 [00:34<00:00, 24485.54it/s]\n",
      "Generating arguments: 100%|████████████████████████████████████████████████| 850000/850000 [00:04<00:00, 170876.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Queries:   0%|                                                                           | 0/850000 [00:00<?, ?query/s]"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(settings)\n",
    "experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa475623-1ba9-4bee-adff-cbae0eb8a3ea",
   "metadata": {},
   "source": [
    "# Read result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cbcf2bf-90be-42df-be98-bd44e3e120e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>settings</th>\n",
       "      <th>distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Proxy Record Customizable Manager?</td>\n",
       "      <td>{'N': 11, 'k': 8, 'pn': [0.32, 0.0, 0.56, 0.11]}</td>\n",
       "      <td>{'645696': 2, '132239': 1, '700503': 2, '47508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Proxy Record Customizable Manager?</td>\n",
       "      <td>{'N': 21, 'k': 13, 'pn': [0.19, 0.53, 0.08, 0....</td>\n",
       "      <td>{'158554': 2, '39779': 1, '565416': 1, '461731...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Proxy Record Customizable Manager?</td>\n",
       "      <td>{'N': 25, 'k': 19, 'pn': [0.2, 0.5, 0.07, 0.23]}</td>\n",
       "      <td>{'46166': 2, '733536': 1, '461731': 2, '158554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Proxy Record Customizable Manager?</td>\n",
       "      <td>{'N': 12, 'k': 9, 'pn': [0.22, 0.04, 0.02, 0.71]}</td>\n",
       "      <td>{'658043': 2, '132239': 1, '551126': 2, '47508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is Proxy Record Customizable Manager?</td>\n",
       "      <td>{'N': 23, 'k': 22, 'pn': [0.47, 0.02, 0.25, 0....</td>\n",
       "      <td>{'603747': 2, '780573': 1, '210987': 1, '15855...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0  Is Proxy Record Customizable Manager?   \n",
       "1  Is Proxy Record Customizable Manager?   \n",
       "2  Is Proxy Record Customizable Manager?   \n",
       "3  Is Proxy Record Customizable Manager?   \n",
       "4  Is Proxy Record Customizable Manager?   \n",
       "\n",
       "                                            settings  \\\n",
       "0   {'N': 11, 'k': 8, 'pn': [0.32, 0.0, 0.56, 0.11]}   \n",
       "1  {'N': 21, 'k': 13, 'pn': [0.19, 0.53, 0.08, 0....   \n",
       "2   {'N': 25, 'k': 19, 'pn': [0.2, 0.5, 0.07, 0.23]}   \n",
       "3  {'N': 12, 'k': 9, 'pn': [0.22, 0.04, 0.02, 0.71]}   \n",
       "4  {'N': 23, 'k': 22, 'pn': [0.47, 0.02, 0.25, 0....   \n",
       "\n",
       "                                        distribution  \n",
       "0  {'645696': 2, '132239': 1, '700503': 2, '47508...  \n",
       "1  {'158554': 2, '39779': 1, '565416': 1, '461731...  \n",
       "2  {'46166': 2, '733536': 1, '461731': 2, '158554...  \n",
       "3  {'658043': 2, '132239': 1, '551126': 2, '47508...  \n",
       "4  {'603747': 2, '780573': 1, '210987': 1, '15855...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = pd.read_csv('../data/results.csv')\n",
    "display(df_results.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89321f84-3b10-41f1-91a0-a4cb47c816b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
