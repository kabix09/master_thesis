{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f01a8400-5267-4dd5-a990-dee8d8f666a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a215b64-f49e-4977-ae7c-0607c057c5e0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557cdf4-d508-4277-8744-10035a3aa96b",
   "metadata": {},
   "source": [
    "Queries generator will use set of four lists with static words:\n",
    "1. Nouns\n",
    "2. Verbs\n",
    "3. Adjectives\n",
    "4. Gerund (participles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51621b63-98bc-49a3-981e-411bded57aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie można znaleźć pliku ../data/raw/gerounds.csv, pomijam...\n"
     ]
    }
   ],
   "source": [
    "collections = [\"nouns\", \"verbs\", \"adjectives\", \"participles\", \"gerounds\"]\n",
    "dfs = {}\n",
    "\n",
    "for name in collections:\n",
    "    column_name = name.capitalize()\n",
    "    csv_path = f\"../data/raw/{name}.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, header=None, names=[column_name])\n",
    "        dfs[name] = df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Nie można znaleźć pliku {csv_path}, pomijam...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd podczas odczytu pliku {csv_path}: {e}\")\n",
    "\n",
    "nouns_df = dfs[\"nouns\"]\n",
    "verbs_df = dfs[\"verbs\"]\n",
    "adjectives_df = dfs[\"adjectives\"]\n",
    "participles_df = dfs[\"participles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d1cd9-082d-4945-be63-9929e8173a7e",
   "metadata": {},
   "source": [
    "## Query generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39c2c1-0ee7-4ac2-a696-fb1b52c7fe0b",
   "metadata": {},
   "source": [
    "Sample code snippet to generate sentences that are candidate phrases for search queries. Which will be used in a search engine to find articles on a similar topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297b44f1-1f2e-4cf3-9879-6f1bb6e078c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generator(nouns, verbs, adjectives, participles, limit):\n",
    "    generated_queries = set()\n",
    "    \n",
    "    while len(generated_queries) < limit:\n",
    "        noun = random.choice(nouns)[0]\n",
    "        verb = random.choice(verbs)[0]\n",
    "        adjective = random.choice(adjectives)[0]\n",
    "        participle = random.choice(participles)[0]\n",
    "        \n",
    "        query = f\"{noun} {verb} {adjective} {participle}\"\n",
    "        \n",
    "        if query not in generated_queries:\n",
    "            generated_queries.add(query)\n",
    "            yield query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce411832-950a-4db0-8343-ae325fdf4b3d",
   "metadata": {},
   "source": [
    "### 1. Language Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd19d5b-d9c0-4d2f-9c18-45201e343915",
   "metadata": {},
   "source": [
    "First attempt to make queries more natrual with `Language Tool` library\n",
    "\n",
    "Source: [Githube](https://github.com/Findus23/pyLanguagetool) </br>\n",
    "Tutorial: [here](https://www.kaggle.com/code/yeoyunsianggeremie/how-to-use-language-tool-python-without-internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26639521-a737-42ef-b45d-ecc642233dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_tool_python import LanguageTool\n",
    "\n",
    "def correct_sentence_lt(sentence: list, debug: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Corrects a sentence using LanguageTool.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The sentence to correct.\n",
    "        debug (bool, optional): A flag indicating whether to display matches, defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The corrected sentence.\n",
    "    \"\"\"\n",
    "    lt = LanguageTool('en-US')\n",
    "    matches = lt.check(sentence)\n",
    "\n",
    "    if debug:\n",
    "        display(matches)\n",
    "\n",
    "    return lt.correct(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db01f5-39d8-4d15-b853-92c542ed694b",
   "metadata": {},
   "source": [
    "### 2. Gramformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a57f2-6111-45e6-a532-3a94c237147c",
   "metadata": {},
   "source": [
    "Second attempt to build more consistent sentences this time with `Gramformer`\n",
    "\n",
    "Source: [Githube](https://github.com/thevkrant/gramformer) </br>\n",
    "Tutorial: [here](https://www.vennify.ai/gramformer-correct-grammar-transformer-nlp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68450b7-0416-4ddd-bd13-d38c4cb7a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gramformer import Gramformer\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    else:\n",
    "        print(f\"`Cuda` is unavailable\")\n",
    "\n",
    "def correct_sentence_gf(gf: Gramformer, sentence: str, debug = False) -> str:\n",
    "    \"\"\"\n",
    "    Corrects a sentence using Gramformer.\n",
    "\n",
    "    Args:\n",
    "        gf (Gramformer): The Gramformer object to use for correction.\n",
    "        sentence (str): The sentence to correct.\n",
    "        debug (bool, optional): A flag indicating whether to display matches, defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The corrected sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    return gf.correct(sentence, max_candidates=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15be417",
   "metadata": {},
   "source": [
    "In this section, we tested two libraries for automatic sentence correction: LanguageTool and Gramformer. The first tool (LanguageTool) did not perform very well and often failed to improve the sentences meaningfully. In contrast, Gramformer generally produced better and more fluent sentence corrections.\n",
    "\n",
    "However, the final decision was to retain the raw version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b00c92-337c-48ca-817b-2d71e4afe8c5",
   "metadata": {},
   "source": [
    "## Prepare queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b3447-b416-4ff7-8f1e-fb8a40a96626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries = query_generator(\n",
    "    nouns_df.values.tolist(), \n",
    "    verbs_df.values.tolist(), \n",
    "    adjectives_df.values.tolist(), \n",
    "    participles_df.values.tolist(), \n",
    "    850000\n",
    ")\n",
    "\n",
    "queries_df = pd.DataFrame({'query': queries})\n",
    "\n",
    "queries_df.drop_duplicates(subset=['query'])\n",
    "\n",
    "unique_queries_count = len(queries_df['query'].unique())\n",
    "print(f\"Obtained {unique_queries_count} unique queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769b8d7-1f31-4c07-b57d-3788c6c11a9b",
   "metadata": {},
   "source": [
    "### Generate embeddings for queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc88f6-c6c2-465e-98ce-07a4c8425633",
   "metadata": {},
   "source": [
    "We generate embeddings for raw queries to expedite the target experiment. By querying the vector database ChromaDB with pre-embedded content, we offload the burden of embedding the raw query received in the request before searching and returning the K most similar titles of scientific papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09f3902-0f5a-4b39-b1a5-0adff8e58511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available: \", torch.cuda.is_available())   \n",
    "    print(\"Number of CUDA devices: \", torch.cuda.device_count())\n",
    "    print(\"CUDA current device: \", torch.cuda.current_device())\n",
    "    print(\"CUDA device name: \", torch.cuda.get_device_name(0))\n",
    "\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cuda')\n",
    "else:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1650e6-16c4-4930-8fd2-be0f30465676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available:  True\n",
      "Number of CUDA devices:  1\n",
      "CUDA current device:  0\n",
      "CUDA device name:  NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding titles: 100%|██████████████████████████████████████████████████████████████| 425/425 [05:49<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "titles = queries_df['query'].tolist()\n",
    "batch_size = 2000\n",
    "\n",
    "titles_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(titles), batch_size), desc=\"Embedding titles\"):\n",
    "    batch = titles[i:i + batch_size]\n",
    "    batch_embeddings = model.encode(batch)\n",
    "    titles_embeddings.extend(batch_embeddings)\n",
    "\n",
    "queries_df['embedding'] = titles_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805471e-028d-41e0-b286-555ad4cd979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df.to_pickle('..//data//interim//queries_with_embeddings.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
